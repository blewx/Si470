{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98870f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in packages\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4a5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to directories\n",
    "currentdir = os.getcwd()\n",
    "inputdir = osp.realpath(osp.join(currentdir, '..', 'inputData'))\n",
    "moogaldir = osp.realpath(osp.join(currentdir, '..', 'MOOGALdefs'))\n",
    "outputdir = osp.realpath(osp.join(currentdir, '..', 'outputData'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b5eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core files\n",
    "indexfile = pd.read_csv(inputdir + '/indexfile.csv')\n",
    "indexfile.set_index(['countryISO3', 'year'], inplace=True)\n",
    "\n",
    "country_name_database = pd.read_csv(inputdir + '/country_regions.csv')\n",
    "\n",
    "demography = pd.read_csv(inputdir + '/demography.csv')\n",
    "demography.set_index(['countryISO3','year'], inplace=True)\n",
    "\n",
    "youth = pd.read_csv(inputdir + '/youth_model.csv')\n",
    "youth.rename(columns={'education': 'education_research', 'active_recreation': 'active_rec',\n",
    "                                             'work_employed': 'work_employment'}, inplace=True)\n",
    "\n",
    "youth_uncertainty = pd.read_csv(inputdir + '/youth_model_unc.csv')\n",
    "youth_uncertainty.rename(columns={'education': 'education_research', 'active_recreation': 'active_rec',\n",
    "                                             'work_employed': 'work_employment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84f9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all TUS to be included into dictionary. Key=country_year, value=df\n",
    "TUS_data = {}\n",
    "\n",
    "for idx, row in indexfile.iterrows():\n",
    "\n",
    "    country = idx[0]\n",
    "    year = int(idx[1])\n",
    "\n",
    "    if row['include'] == 1:\n",
    "\n",
    "        fname = row['TUS_file']\n",
    "\n",
    "        TUS_data[country + '_' + str(year)] = \\\n",
    "            pd.read_csv(inputdir + '/' + fname, sep=',')[['tier1','tier2','hours_per_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a91e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce all TUS to sum to 24h (minor differences are redistributed proportionally to all activities)\n",
    "TUS_dict = {}\n",
    "\n",
    "for k, v in TUS_data.items():\n",
    "\n",
    "    # Country ISO3 code is first 3 substrings, year is 4th+ of key (ISO_YYYY)\n",
    "    country = k[0:3]\n",
    "    year = int(k[4:])\n",
    "\n",
    "    # Take only first 3 columns\n",
    "    tus = v[['tier1','tier2','hours_per_day']].copy()\n",
    "    hours_sum = v['hours_per_day'].sum()\n",
    "\n",
    "    # Check and adjust hours to equal 24 (proportionally distributed)\n",
    "    if hours_sum >= 24.01:\n",
    "        difference = tus['hours_per_day'].sum() - 24.0\n",
    "        tus['hours_per_day'] = tus['hours_per_day'].apply(lambda t: t - (difference * t / hours_sum))\n",
    "        tus['tier1'] = tus.iloc[:,0].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "        tus['tier2'] = tus.iloc[:,1].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "        TUS_dict[country + '_' + str(year)] = tus\n",
    "        \n",
    "    elif hours_sum <= 23.99:\n",
    "        difference = 24.0 - tus['hours_per_day'].sum()\n",
    "        tus['hours_per_day'] = tus['hours_per_day'].apply(lambda t: t + (difference * t / hours_sum))\n",
    "        tus['tier1'] = tus.iloc[:,0].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "        tus['tier2'] = tus.iloc[:,1].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "        TUS_dict[country+ '_' + str(year)] = tus\n",
    "    \n",
    "    else:\n",
    "        tus['tier1'] = tus.iloc[:,0].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "        tus['tier2'] = tus.iloc[:,1].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "        TUS_dict[country+ '_' + str(year)] = tus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5989ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MLdef files, split into MLdef (fractions) and MLunc\n",
    "MLdef_dict = {}\n",
    "MLunc_dict = {}\n",
    "\n",
    "for k, v in TUS_dict.items():\n",
    "    \n",
    "    MLdef = {}\n",
    "    MLunc = {}\n",
    "    country = k[0:3]\n",
    "    year = int(k[4:])\n",
    "    \n",
    "    # Find MLdef file in indexfile\n",
    "    file = indexfile.loc[country].loc[year]['TUS_MLdef']\n",
    "\n",
    "    # Take first 30 cols of MLdef (avoids taking empty cols)\n",
    "    combined_MLdef = pd.read_csv(moogaldir + '/' + file, usecols = np.arange(0,30))\n",
    "\n",
    "    # Drop hours_per_day col since it will be replaced directly with TUS data\n",
    "    combined_MLdef.drop('hours_per_day', axis=1, inplace=True)\n",
    "    \n",
    "    # Lowercase all strings and remove whitespaces on either side to avoid errors when merging\n",
    "    MLdef['tier1'] = combined_MLdef.iloc[:,0].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "    MLdef['tier2'] = combined_MLdef.iloc[:,1].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "    MLunc['tier1'] = combined_MLdef.iloc[:,0].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "    MLunc['tier2'] = combined_MLdef.iloc[:,1].str.lower().str.lstrip(' ').str.rstrip(' ')\n",
    "\n",
    "    for col in combined_MLdef.iloc[:, 2:]:\n",
    "        \n",
    "        # Split the column on the ; -- 1st item is MLdef frac, 2nd item is MLunc\n",
    "        split_MLdef = combined_MLdef[col].apply(lambda x: x.split(\";\")[0]).replace('nan', 0)\n",
    "        # Some items are numbers in string form (thx excel) so force to numeric\n",
    "        split_MLdef = split_MLdef.apply(pd.to_numeric, errors='coerce')\n",
    "        MLdef[col] = split_MLdef\n",
    "\n",
    "        split_MLunc = combined_MLdef[col].apply(lambda x: x.split(';')[1]).replace('nan', np.NaN)\n",
    "        split_MLunc = split_MLunc.apply(pd.to_numeric, errors='coerce')\n",
    "        MLunc[col] = split_MLunc\n",
    "    \n",
    "    MLdef = pd.DataFrame.from_dict(MLdef)\n",
    "    MLunc = pd.DataFrame.from_dict(MLunc)\n",
    "    MLdef_dict[k] = MLdef\n",
    "    MLunc_dict[k] = MLunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c23da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TUS classification to MOOGAL\n",
    "TUS_M24 = {}\n",
    "baseline_uncertainty = {'A':0.05, 'B':0.1, 'C':0.2}\n",
    "\n",
    "for k, v in TUS_dict.items():\n",
    "    \n",
    "    country = k[0:3]\n",
    "    year = int(k[4:])\n",
    "    \n",
    "    # Merge TUS with MLdef\n",
    "    merged = v.merge(MLdef_dict[k], on=['tier1','tier2'])\n",
    "    \n",
    "    t = np.array(merged['hours_per_day']).reshape((1,len(merged)))\n",
    "    M = np.array(merged.iloc[:,3:])\n",
    "    \n",
    "    # t (1 x n) * M [n x 27] = h (1 x 27)\n",
    "    h = np.dot(t,M)\n",
    "\n",
    "    # Redistribute \"unknown\" proportionally across all categories, then drop unknown column\n",
    "    unknown = h[0,-1]\n",
    "    h = np.delete(h, -1)\n",
    "    scale = (lambda x: unknown * x / (h.sum() + unknown) + x)\n",
    "    h = scale(h)\n",
    "    \n",
    "    # Compute uncertainty\n",
    "    merged = v.merge(MLunc_dict[k], on=['tier1','tier2'])\n",
    "    u_base = baseline_uncertainty[indexfile.loc[country].loc[year]['tus_quality']]\n",
    "    \n",
    "    U_frac = merged.iloc[:,3:] \n",
    "    # Sum variance of MLunc fraction with baseline variance, multiply by square of time,\n",
    "    # following formula of combined_var = w^2 * sigma^2 \n",
    "    U = np.nansum(t.T**2 * U_frac**2 + t.T**2 * u_base**2 , axis=0)\n",
    "    U = np.delete(U, -1)\n",
    "    \n",
    "    # Convert hours & uncertainty to df with index of subcategories\n",
    "    subcategories = merged.columns[3:-1]\n",
    "    TUS_M24[k] = pd.DataFrame(data=zip(h,U), index=subcategories, columns=['hours_per_day','uncertainty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4bcafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate youth model\n",
    "\n",
    "# First, clean it up\n",
    "youth['countryISO3'] = youth.iloc[:,0].apply(lambda x: x[2:5])\n",
    "youth['age'] = youth.iloc[:,0].apply(lambda x: int(re.findall(\"\\d+\", x)[0]))\n",
    "youth.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "youth.set_index(['countryISO3', 'age'], inplace=True)\n",
    "\n",
    "youth_uncertainty['countryISO3'] = youth_uncertainty.iloc[:,0].apply(lambda x: x[2:5])\n",
    "youth_uncertainty['age'] = youth_uncertainty.iloc[:,0].apply(lambda x: int(re.findall(\"\\d+\", x)[0]))\n",
    "youth_uncertainty.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "youth_uncertainty.set_index(['countryISO3', 'age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2eed4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine it with TUS according to population covered in each.\n",
    "\n",
    "TUS_combined_M24 = {}\n",
    "TUS_country_year = {}\n",
    "\n",
    "for k, v in TUS_M24.items():\n",
    "    \n",
    "    country = k[0:3]\n",
    "    year = int(k[4:])\n",
    "        \n",
    "    min_age = indexfile.loc[country].loc[year]['TUS_age_min']\n",
    "    max_age = indexfile.loc[country].loc[year]['TUS_age_max'] + 1\n",
    "    \n",
    "    if min_age == 0:\n",
    "        \n",
    "        TUS_combined_M24[k[0:3]] = v\n",
    "        TUS_country_year[k[0:3]] = int(k[4:])\n",
    "    \n",
    "    else:\n",
    "        youth_hrs_list = []\n",
    "        youth_unc_list = []\n",
    "        \n",
    "        pop_in_TUS = demography.loc[country].loc[year][min_age:max_age].sum()\n",
    "        pop_total = demography.loc[country].loc[year][:max_age].sum()\n",
    "        \n",
    "        person_hours_TUS = v['hours_per_day'] * pop_in_TUS\n",
    "        TUS_uncertainty = v['uncertainty'] * ((pop_in_TUS/pop_total)**2)\n",
    "        \n",
    "        for age in np.arange(0, min_age):\n",
    "\n",
    "            # Access row of activities for given country and age\n",
    "            youth_hours = youth.loc[country].loc[age]\n",
    "            # Nothing in unknown so drop it for simplicity\n",
    "            youth_hours.drop('unknown', axis=0, inplace=True)\n",
    "\n",
    "            # Get population of age, multiply by avg hours\n",
    "            pop_youth = demography.loc[country].loc[year][age]\n",
    "            youth_person_hours = youth_hours * pop_youth\n",
    "            youth_hrs_list.append(youth_person_hours)\n",
    "            \n",
    "            # Get uncertainty for age (units already in hrs)\n",
    "            youth_unc = youth_uncertainty.loc[country].loc[age]\n",
    "            youth_unc.drop('unknown', axis=0, inplace=True)\n",
    "            # Youth baseline uncertainty\n",
    "            unc_base = 0.25**2 * youth_hours**2\n",
    "            # Add weighted variances\n",
    "            youth_unc = (youth_unc**2 + unc_base) * (pop_youth / pop_total)**2\n",
    "            youth_unc_list.append(youth_unc)\n",
    "        \n",
    "        # Sum across ages to get youth total person-hours, add to TUS person-hours, then divide by total pop\n",
    "        total_youth_hours = pd.DataFrame(youth_hrs_list).sum()\n",
    "        \n",
    "        combined_hours = (person_hours_TUS.values + total_youth_hours) / pop_total\n",
    "        \n",
    "        # Add variances from TUS and youth together\n",
    "        total_youth_uncertainty = (pd.DataFrame(youth_unc_list)).sum()\n",
    "        combined_uncertainty = (TUS_uncertainty + total_youth_uncertainty) \n",
    "        \n",
    "        TUS_combined_M24[k[0:3]] = pd.DataFrame(data=zip(np.array(combined_hours), \\\n",
    "                                                np.array(combined_uncertainty)), index=combined_hours.index, \\\n",
    "                                                columns=['hours_per_day','uncertainty'])\n",
    "        TUS_country_year[k[0:3]] = int(k[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80160239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split combined dict into separate dfs\n",
    "hours = pd.DataFrame([TUS_combined_M24[i]['hours_per_day'] for i in TUS_combined_M24.keys()], \\\n",
    "                     index=TUS_combined_M24.keys())\n",
    "uncertainty = pd.DataFrame([TUS_combined_M24[i]['uncertainty'] for i in TUS_combined_M24.keys()], \\\n",
    "                        index=TUS_combined_M24.keys())\n",
    "\n",
    "# Format hours df for interpolation\n",
    "hours = hours.reset_index().rename(columns={'index':'countryISO3'}).melt(id_vars=['countryISO3'], \\\n",
    "                        var_name='subcategory', value_name='hoursPerDay')\n",
    "hours = hours.merge(country_name_database[['region_code','country_iso3']], how='left', left_on='countryISO3', \\\n",
    "                        right_on='country_iso3').drop('country_iso3', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4434be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate TUS data over regions \n",
    "\n",
    "hours_region_group = hours.groupby(['region_code','subcategory'])\n",
    "no_pop_data = []\n",
    "M24_interpolated = []\n",
    "\n",
    "for name, grp in hours_region_group:\n",
    "    \n",
    "    countries_in_region = list(country_name_database[country_name_database['region_code'] == \\\n",
    "                            name[0]]['country_iso3'])\n",
    "    df = pd.DataFrame()\n",
    "    df['countryISO3'] = countries_in_region\n",
    "    df = df.merge(grp, on='countryISO3', how='left')\n",
    "    df.fillna({'region_code':name[0], 'subcategory':name[1]}, inplace=True)\n",
    "    \n",
    "    populations = []    \n",
    "    pop_with_data = []\n",
    "    unc = []\n",
    "    \n",
    "    for country in df['countryISO3'].unique():\n",
    "        \n",
    "        # No pop data for protectorates and unrecognzied entities. Exclude.\n",
    "        if country not in set(demography.index.get_level_values(0)):\n",
    "            no_pop_data.append(country)\n",
    "            populations.append(np.NaN)\n",
    "            unc.append(np.NaN)\n",
    "            \n",
    "        elif country in TUS_country_year.keys():\n",
    "            year = TUS_country_year[country]\n",
    "            max_age = indexfile.loc[country].loc[year]['TUS_age_max'] + 1\n",
    "            populations.append(demography.loc[country].loc[year][:max_age].sum())\n",
    "            pop_with_data.append(demography.loc[country].loc[year][:max_age].sum())\n",
    "            unc.append(uncertainty.loc[country][name[1]])\n",
    "        \n",
    "        else:\n",
    "            populations.append(demography.loc[country].loc[2019][:].sum())\n",
    "            unc.append(np.NaN)\n",
    "            \n",
    "    df['population'] = populations\n",
    "    pop_with_data = np.sum(pop_with_data)\n",
    "    \n",
    "    df['dataStatus'] = ['observed' if i >= 0.0 else 'interpolated' for i in df['hoursPerDay']]\n",
    "    \n",
    "    region_stdev = df['hoursPerDay'].std()\n",
    "    df['uncertainty'] = unc\n",
    "    \n",
    "    if df['dataStatus'].value_counts()['observed'] <= 3:\n",
    "        global_stdev = hours.groupby('subcategory')['hoursPerDay'].std().loc[name[1]]\n",
    "        u = df['uncertainty'].loc[~df['uncertainty'].isnull()].iloc[0]\n",
    "        df['uncertainty'] = df['uncertainty'].fillna((2*global_stdev)**2 + u)\n",
    "               \n",
    "    else:  \n",
    "        df['uncertainty'] = df['uncertainty'].fillna(region_stdev**2)\n",
    "    \n",
    "    region_mean = (df['hoursPerDay'] * df['population']).sum() / pop_with_data\n",
    "    df['hoursPerDay'] = df['hoursPerDay'].fillna(region_mean)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "       \n",
    "    M24_interpolated.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6595c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M24_interpolated = pd.concat(M24_interpolated)\n",
    "M24_interpolated = M24_interpolated[['countryISO3','region_code','population',\\\n",
    "                                     'subcategory','hoursPerDay','uncertainty','dataStatus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a18ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "current_date = datetime.today().strftime('%y%m%d')\n",
    "M24_interpolated.to_csv(outputdir + '/M24_TUS_and_youth_' + current_date + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1a8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
